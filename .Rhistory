library(car)
crPlots(mod1)
mod2 <- lm(Y~.+X1^2, data=dat)
summary(mod2)
crPlot(mod2)
mod2 <- lm(Y~X1+X2+X3+X1^2, data=dat)
summary(mod2)
.
mod2 <- lm(Y~.+X1^2, data=dat)
summary(mod2)
2+X3
mod2 <- lm(Y~X1+X2+X3+X1^2, data=dat)
summary(mod2)
mod2 <- lm(Y~.+X1**2, data=dat)
summary(mod2)
crPlot(mod2)
mod2 <- lm(Y~.+X1**2, data=dat)
summary(mod2)
crPlot(mod2)
mod2 <- lm(Y~.+X1**2, data=dat)
summary(mod2)
crPlot(mod2)
mod2 <- lm(Y~.+X1**2, data=dat)
summary(mod2)
crPlot(mod2)
3^2
mod2 <- lm(Y~.+I(X1^2), data=dat)
summary(mod2)
crPlot(mod2)
mod2 <- lm(Y~.+I(X1^2), data=dat)
summary(mod2)
crPlot(mod2)
dat2$X1^2 <- X1^2
dat2 <- dat
dat2$X1^2 <- X1^2
dat2 <- dat
dat2$X1_2 <- X1^2
mod2 <- lm(Y~.+I(X1^2), data=dat)
summary(mod2)
crPlot(mod2)
dat2 <- dat
dat2$X1_2 <- X1^2
mod2 <- lm(Y~., data=dat2)
summary(mod2)
crPlot(mod2)
dat2 <- dat
dat2$
mod2 <- lm(Y~.+I(X1^2), data=dat)
dat2 <- dat
mod2 <- lm(Y~.+I(X1^2), data=dat)
summary(mod2)
crPlots(mod2)
mod3 <- lm(Y~.+X1^2+X1^3, data=dat)
summary(mod3)
crPlots(mod3)
mod3 <- lm(Y~.+I(X1^2)+I(X1^3), data=dat)
summary(mod3)
crPlots(mod3)
mod3 <- lm(Y~.+I(X1^2)+I(X3^2), data=dat)
summary(mod3)
crPlots(mod3)
detach(dat)
wine <- read.csv("winequality.csv")
attach(wine)
wine
mod_wine <- lm(quality~., data=wine)
summary(mod_wine)
crPlots(mod_wine)
knitr::opts_chunk$set(echo = TRUE)
dat <- read.csv("HW22.csv")
attach(dat)
mod1 <- lm(Y ~ ., data=dat)
summary(mod1)
par(mfrow=c(2,2))
plot(fitted(mod1), resid(mod1), main="Residuals vs Fitted Values",
xlab="Fitted Values", ylab="Residuals")
plot(X1, Y, main="X1 vs Y", xlab="X1", ylab="Y")
plot(X2, Y, main="X2 vs Y", xlab="X2", ylab="Y")
plot(X3, Y, main="X3 vs Y", xlab="X3", ylab="Y")
library(car)
crPlots(mod1)
mod2 <- lm(Y~.+I(X1^2), data=dat)
summary(mod2)
crPlots(mod2)
mod3 <- lm(Y~.+I(X1^2)+I(X3^2), data=dat)
summary(mod3)
crPlots(mod3)
detach(dat)
wine <- read.csv("winequality.csv")
attach(wine)
mod_wine <- lm(quality~., data=wine)
summary(mod_wine)
round(cor(X),3)
X <- scale(as.matrix(wine[,-1]))
round(cor(X),3)
pairs(X)
View(mod_wine)
View(wine)
X <- scale(as.matrix(wine[,-12]))
round(cor(X),3)
e <- eigen(t(X)%*%X)
e
V <- e$vectors
lam <- e$values
plot(lam, xlab='Eigenvalue Number', ylab='Eigenvalue Size', main='Scree Plot')
lines(lam)
pi <- lam/sum(lam)
pi
pi.cumul <- c()
for (i in 1:length(lam)) {
pi.cumul[i] <- sum(pi[1:i])
}
pi.cumul
plot(pi.cumul, xlab='Eigenvalue Number', ylab='Cumulative Proportion', main='')
lines(pi.cumul)
abline(0.85, 0, lty=2)
abline(0.90, 0, lty=2)
abline(0.95, 0, lty=2)
diag(var(Z))
Z <- X%*%V
diag(var(Z))
pcr <- lm(quality ~ Z)
summary(pcr)
Z
Z <- X%*%V
diag(var(Z))
pcr <- lm(quality ~ Z[,1:8])
summary(pcr)
pcr <- lm(quality ~ Z[,1:9])
summary(pcr)
pcr <- lm(quality ~ Z[,1:11])
summary(pcr)
pcr <- lm(quality ~ Z[,1:7])
summary(pcr)
pcr <- lm(quality ~ Z[,1:6])
summary(pcr)
pcr <- lm(quality ~ Z[,1:5])
summary(pcr)
pcr <- lm(quality ~ Z[,1:6])
summary(pcr)
b_hat_pca <- as.matrix(pcr$coefficients[2:7], nr=6)
b_hat_pca <- as.matrix(pcr$coefficients[2:7], nr=6)
b_hat <- V%*%b_hat_pca
pcr2 <- lm(quality ~ Z)
b_hat_pca <- as.matrix(pcr2$coefficients[2:12], nr=11)
b_hat <- V%*%b_hat_pca
b_hat
\texttt{curve()}
knitr::opts_chunk$set(echo = TRUE)
\texttt{curve()}
curve(exp(0-2 + 1*x)/(1 + exp(-2 + 1*x)), from=-10, to=10, lwd=2, xlab="x", ylab="pi")
curve(exp(0 + 1*x)/(1 + exp(0 + 1*x)), from=-10, to=10, lwd=2, xlab="x", ylab="pi")
curve(exp(2 + 1*x)/(1 + exp(2 + 1*x)), from=-10, to=10, lwd=2, xlab="x", ylab="pi")
curve(exp(0-2 + 1*x)/(1 + exp(-2 + 1*x)), from=-10, to=10, lwd=2, xlab="x", ylab="pi")
curve(exp(0 + 1*x)/(1 + exp(0 + 1*x)), from=-10, to=10, lwd=2, xlab="x", ylab="pi")
curve(exp(2 + 1*x)/(1 + exp(2 + 1*x)), from=-10, to=10, lwd=2, xlab="x", ylab="pi")
curve(exp(0-2 + 1*x)/(1 + exp(-2 + 1*x)), from=-10, to=10, lwd=2, xlab="x", ylab="pi")
knitr::opts_chunk$set(echo = TRUE)
curve(exp(0 + 1*x)/(1 + exp(0 + 1*x)), from=-10, to=10, lwd=2, xlab="x", ylab="pi")
curve(exp(2 + 1*x)/(1 + exp(2 + 1*x)), from=-10, to=10, lwd=2, xlab="x", ylab="pi")
curve(exp(0-2 + 1*x)/(1 + exp(-2 + 1*x)), from=-10, to=10, lwd=2, xlab="x", ylab="pi")
curve(exp(0 + 1*x)/(1 + exp(0 + 1*x)), from=-10, to=10, lwd=2, xlab="x", ylab="pi")
curve(exp(2 + 1*x)/(1 + exp(2 + 1*x)), add=TRUE, col="blue", type="1")
curve(exp(0 + 1*x)/(1 + exp(0 + 1*x)), from=-10, to=10, lwd=2, xlab="x", ylab="pi")
curve(exp(2 + 1*x)/(1 + exp(2 + 1*x)), add=TRUE, col="blue", type="l")
curve(exp(-2 + 1*x)/(1 + exp(-2 + 1*x)), add=TRUE, col="red", type="l")
knitr::opts_chunk$set(echo = TRUE)
x25 <- read.csv("X25.csv")
x25 <- read.csv("X25.csv")
spam <- read.csv("spam.csv")
spam.train <- spam[spam$test.id==FALSE,-59]
spam.test <- spam[spam$test.id==TRUE,-59]
View(spam)
cv.glmnet(x=spam.train[,-58],y=spam.train[,58],family="binomial",type.measure="class")
library(glmnet)
cv.glmnet(x=spam.train[,-58],y=spam.train[,58],family="binomial",type.measure="class")
library(glmnet)
cv.glmnet(x=as.matrix(spam.train[,-58]),y=as.matrix(spam.train[,58]),
family="binomial",type.measure="class")
library(glmnet)
lasso_cv <- cv.glmnet(x=as.matrix(spam.train[,-58]),y=as.matrix(spam.train[,58]),
family="binomial",type.measure="class")
plot(lasso_cv, main="Lambda Values for Ridge Regression with Cross-Validation")
lasso_cv$lambda.min
lasso_cv$lambda.1se
# Question 1
## 1.
### a.
```{r}
pi <- (exp(X*Beta)) / (1+exp(X*Beta))
x25 <- read.csv("X25.csv")
X <- as.matrix(x25)
Beta <- matrix(c(0,0.2,-0.2,0.3,-0.3),5,1)
pi <- (exp(X*Beta)) / (1+exp(X*Beta))
X
pi <- (exp(X%*%Beta)) / (1+exp(X%*%Beta))
x25 <- read.csv("X25.csv")
X <- as.matrix(x25)
Beta <- matrix(c(0.2,-0.2,0.3,-0.3),4,1)
pi <- (exp(X*Beta)) / (1+exp(X*Beta))
Beta
X
x25 <- read.csv("X25.csv")
X <- as.matrix(x25)
Beta <- matrix(c(0.2,-0.2,0.3,-0.3),4,1)
pi <- (exp(X*Beta)) / (1+exp(X*Beta))
x25 <- read.csv("X25.csv")
X <- as.matrix(x25)
Beta <- matrix(c(0.2,-0.2,0.3,-0.3),4,1)
pi <- (exp(X%*%Beta)) / (1+exp(X%*%Beta))
X
pi
rbinom(n,size=1,prob=pi)
rbinom(25,size=1,prob=pi)
n <- nrow(x25)
for (i in 1:1000) {
y_i <- rbinom(n,size=1,prob=pi)
this_mod <- glm(y_i ~ ., data=X, family=binomial(link="logit"))
}
n <- nrow(x25)
for (i in 1:1000) {
y_i <- rbinom(n,size=1,prob=pi)
this_mod <- glm(y_i ~ ., data=as.data.frame(X), family=binomial(link="logit"))
}
n <- nrow(x25)
Betas <- matrix(NA,1000,4)
for (i in 1:1000) {
y_i <- rbinom(n,size=1,prob=pi)
this_mod <- glm(y_i ~ ., data=as.data.frame(X), family=binomial(link="logit"))
Betas[i,] <- this_mod$coefficients[-1]
}
Betas
par(mfrow=c(4,2))
for (i in 1:4) {
hist(Betas[,i])
qqnorm(Betas[,i])
qqline(Betas[,i])
}
knitr::opts_chunk$set(echo = TRUE)
x25 <- read.csv("X25.csv")
X <- as.matrix(x25)
Beta <- matrix(c(0.2,-0.2,0.3,-0.3),4,1)
pi <- (exp(X%*%Beta)) / (1+exp(X%*%Beta))
n <- nrow(x25)
Betas <- matrix(NA,1000,4)
for (i in 1:1000) {
y_i <- rbinom(n,size=1,prob=pi)
this_mod <- glm(y_i ~ ., data=as.data.frame(X), family=binomial(link="logit"))
Betas[i,] <- this_mod$coefficients[-1]
}
par(mfrow=c(4,2))
for (i in 1:4) {
hist(Betas[,i])
qqnorm(Betas[,i])
qqline(Betas[,i])
}
spam <- read.csv("spam.csv")
spam.train <- spam[spam$test.id==FALSE,-59]
spam.test <- spam[spam$test.id==TRUE,-59]
library(glmnet)
lasso_cv <- cv.glmnet(x=as.matrix(spam.train[,-58]),y=as.matrix(spam.train[,58]),
family="binomial",type.measure="class")
plot(lasso_cv, main="Lambda Values for Ridge Regression with Cross-Validation")
lasso_cv$lambda.min
lasso_cv$lambda.1se
par(mfrow=c(4,2), mar=rep(1,4))
for (i in 1:4) {
hist(Betas[,i])
qqnorm(Betas[,i])
qqline(Betas[,i])
}
n <- nrow(x25)
Betas <- matrix(NA,1000,4)
for (i in 1:1000) {
y_i <- rbinom(n,size=1,prob=pi)
this_mod <- glm(y_i ~ ., data=as.data.frame(X), family=binomial(link="logit"))
Betas[i,] <- this_mod$coefficients[-1]
}
Betas <- matrix(NA,1000,4)
for (i in 1:1000) {
y_i <- rbinom(n,size=1,prob=pi)
this_mod <- glm(y_i ~ ., data=x25, family=binomial(link="logit"))
Betas[i,] <- this_mod$coefficients[-1]
}
par(mfrow=c(4,2), mar=rep(1,4))
for (i in 1:4) {
hist(Betas[,i])
qqnorm(Betas[,i])
qqline(Betas[,i])
}
knitr::opts_chunk$set(echo = TRUE)
x25 <- read.csv("X25.csv")
X <- as.matrix(x25)
Beta <- matrix(c(0.2,-0.2,0.3,-0.3),4,1)
pi <- (exp(X%*%Beta)) / (1+exp(X%*%Beta))
n <- nrow(x25)
Betas <- matrix(NA,1000,4)
for (i in 1:1000) {
y_i <- rbinom(n,size=1,prob=pi)
this_mod <- glm(y_i ~ ., data=as.data.frame(X), family=binomial(link="logit"))
Betas[i,] <- this_mod$coefficients[-1]
}
par(mfrow=c(4,2), mar=rep(1,4))
for (i in 1:4) {
hist(Betas[,i])
qqnorm(Betas[,i])
qqline(Betas[,i])
}
x50 <- read.csv("X50.csv")
X <- as.matrix(x50)
Beta <- matrix(c(0.2,-0.2,0.3,-0.3),4,1)
pi <- (exp(X%*%Beta)) / (1+exp(X%*%Beta))
n <- nrow(x50)
Betas <- matrix(NA,1000,4)
for (i in 1:1000) {
y_i <- rbinom(n,size=1,prob=pi)
this_mod <- glm(y_i ~ ., data=as.data.frame(X), family=binomial(link="logit"))
Betas[i,] <- this_mod$coefficients[-1]
}
par(mfrow=c(4,2), mar=rep(1,4))
for (i in 1:4) {
hist(Betas[,i])
qqnorm(Betas[,i])
qqline(Betas[,i])
}
x100 <- read.csv("X100.csv")
X <- as.matrix(x100)
Beta <- matrix(c(0.2,-0.2,0.3,-0.3),4,1)
pi <- (exp(X%*%Beta)) / (1+exp(X%*%Beta))
n <- nrow(x100)
Betas <- matrix(NA,1000,4)
for (i in 1:1000) {
y_i <- rbinom(n,size=1,prob=pi)
this_mod <- glm(y_i ~ ., data=as.data.frame(X), family=binomial(link="logit"))
Betas[i,] <- this_mod$coefficients[-1]
}
par(mfrow=c(4,2), mar=rep(1,4))
for (i in 1:4) {
hist(Betas[,i])
qqnorm(Betas[,i])
qqline(Betas[,i])
}
x25 <- read.csv("X25.csv")
X <- as.matrix(x25)
Beta <- matrix(c(0.2,-0.2,0.3,-0.3),4,1)
pi <- (exp(X%*%Beta)) / (1+exp(X%*%Beta))
n <- nrow(x25)
Betas <- matrix(NA,1000,4)
for (i in 1:1000) {
y_i <- rbinom(n,size=1,prob=pi)
this_mod <- glm(y_i ~ ., data=as.data.frame(X), family=binomial(link="logit"))
Betas[i,] <- this_mod$coefficients[-1]
}
par(mfrow=c(4,2), mar=rep(1,4))
for (i in 1:4) {
hist(Betas[,i])
qqnorm(Betas[,i])
qqline(Betas[,i])
}
spam <- read.csv("spam.csv")
spam.train <- spam[spam$test.id==FALSE,-59]
spam.test <- spam[spam$test.id==TRUE,-59]
library(glmnet)
lasso_cv <- cv.glmnet(x=as.matrix(spam.train[,-58]),y=as.matrix(spam.train[,58]),
family="binomial",type.measure="class")
plot(lasso_cv, main="Lambda Values for Ridge Regression with Cross-Validation")
lasso_cv$lambda.min
lasso_cv$lambda.1se
knitr::opts_chunk$set(echo = TRUE)
x25 <- read.csv("X25.csv")
X <- as.matrix(x25)
Beta <- matrix(c(0.2,-0.2,0.3,-0.3),4,1)
pi <- (exp(X%*%Beta)) / (1+exp(X%*%Beta))
n <- nrow(x25)
Betas <- matrix(NA,1000,4)
for (i in 1:1000) {
y_i <- rbinom(n,size=1,prob=pi)
this_mod <- glm(y_i ~ ., data=as.data.frame(X), family=binomial(link="logit"))
Betas[i,] <- this_mod$coefficients[-1]
}
par(mfrow=c(4,2), mar=rep(2,4))
for (i in 1:4) {
hist(Betas[,i], main=paste("Histogram of Beta", as.character(i)), breaks=60)
qqnorm(Betas[,i])
qqline(Betas[,i])
}
x50 <- read.csv("X50.csv")
X <- as.matrix(x50)
Beta <- matrix(c(0.2,-0.2,0.3,-0.3),4,1)
pi <- (exp(X%*%Beta)) / (1+exp(X%*%Beta))
n <- nrow(x50)
Betas <- matrix(NA,1000,4)
for (i in 1:1000) {
y_i <- rbinom(n,size=1,prob=pi)
this_mod <- glm(y_i ~ ., data=as.data.frame(X), family=binomial(link="logit"))
Betas[i,] <- this_mod$coefficients[-1]
}
par(mfrow=c(4,2), mar=rep(2,4))
for (i in 1:4) {
hist(Betas[,i], main=paste("Histogram of Beta", as.character(i)), breaks=30)
qqnorm(Betas[,i])
qqline(Betas[,i])
}
x100 <- read.csv("X100.csv")
X <- as.matrix(x100)
Beta <- matrix(c(0.2,-0.2,0.3,-0.3),4,1)
pi <- (exp(X%*%Beta)) / (1+exp(X%*%Beta))
n <- nrow(x100)
Betas <- matrix(NA,1000,4)
for (i in 1:1000) {
y_i <- rbinom(n,size=1,prob=pi)
this_mod <- glm(y_i ~ ., data=as.data.frame(X), family=binomial(link="logit"))
Betas[i,] <- this_mod$coefficients[-1]
}
par(mfrow=c(4,2), mar=rep(2,4))
for (i in 1:4) {
hist(Betas[,i], main=paste("Histogram of Beta", as.character(i)), breaks=30)
qqnorm(Betas[,i])
qqline(Betas[,i])
}
x500 <- read.csv("X500.csv")
X <- as.matrix(x500)
Beta <- matrix(c(0.2,-0.2,0.3,-0.3),4,1)
pi <- (exp(X%*%Beta)) / (1+exp(X%*%Beta))
n <- nrow(x500)
Betas <- matrix(NA,1000,4)
for (i in 1:1000) {
y_i <- rbinom(n,size=1,prob=pi)
this_mod <- glm(y_i ~ ., data=as.data.frame(X), family=binomial(link="logit"))
Betas[i,] <- this_mod$coefficients[-1]
}
par(mfrow=c(4,2), mar=rep(2,4))
for (i in 1:4) {
hist(Betas[,i], main=paste("Histogram of Beta", as.character(i)), breaks=30)
qqnorm(Betas[,i])
qqline(Betas[,i])
}
spam <- read.csv("spam.csv")
spam.train <- spam[spam$test.id==FALSE,-59]
spam.test <- spam[spam$test.id==TRUE,-59]
library(glmnet)
lasso_cv <- cv.glmnet(x=as.matrix(spam.train[,-58]),y=as.matrix(spam.train[,58]),
family="binomial",type.measure="class")
plot(lasso_cv, main="Lambda Values for Ridge Regression with Cross-Validation")
lasso_cv$lambda.min
lasso_cv$lambda.1se
lasso_mod <- glmnet(x=as.matrix(spam.train[,-58]),y=as.matrix(spam.train[,58]),
lambda=lasso_cv$lambda.1se, family="binomial")
lasso_mod$beta
pi_pred <- predict(lasso_mod, newx=as.matrix(spam.test[,-58]), type="response")
summary(pi_pred)
pred_results <- c()
for (i in pi_pred) {
if (i>0.5) {
pred_results <- c(pred_results, 1)
}
else {
pred_results <- c(pred_results, 0)
}
}
summary(pred_results)
length(pred_results)
sum(pred_results)
pred_actual <- data.frame(predicted=pred_results, actual=spam.test[,58])
p1a1 <- nrow(pred_actual[pred_actual$predicted==1 & pred_actual$actual==1,])
p1a0 <- nrow(pred_actual[pred_actual$predicted==1 & pred_actual$actual==0,])
p0a1 <- nrow(pred_actual[pred_actual$predicted==0 & pred_actual$actual==1,])
p0a0 <- nrow(pred_actual[pred_actual$predicted==0 & pred_actual$actual==0,])
tab_df <- data.frame("Actual Spam"=c(p1a1,p0a1),
"Actual No-Spam"=c(p1a0,p0a0),
row.names=c("Predicted Spam","Predicted No-Spam"))
knitr::kable(tab_df)
misclf <- (p0a1+p1a0)/nrow(pred_actual)
misclf
sensitivity <- p1a1/(p1a1+p0a1)
sensitivity
specificity <- p0a0/(p1a0+p0a0)
specificity
cutoff <- seq(0.01,0.99, 0.01)
cutoff_df <- data.frame("cutoff"=cutoff, "sensitivity"=NA, "specificity"=NA,
row.names=cutoff)
# for each cut-off prob, recompute predicted outcome based on cut-off
for (p in cutoff) {
pred_results_i <- c()
for (i in pi_pred) {
if (i > p) {
pred_results_i <- c(pred_results_i, 1)
}
else {
pred_results_i <- c(pred_results_i, 0)
}
}
pred_actual_p <- data.frame(predicted=pred_results_i, actual=spam.test[,58])
p1a1_p <- nrow(pred_actual_p[pred_actual_p$predicted==1 & pred_actual_p$actual==1,])
p1a0_p <- nrow(pred_actual_p[pred_actual_p$predicted==1 & pred_actual_p$actual==0,])
p0a1_p <- nrow(pred_actual_p[pred_actual_p$predicted==0 & pred_actual_p$actual==1,])
p0a0_p <- nrow(pred_actual_p[pred_actual_p$predicted==0 & pred_actual_p$actual==0,])
sens_p <- p1a1_p/(p1a1_p+p0a1_p)
spec_p <- p0a0_p/(p1a0_p+p0a0_p)
cutoff_df[cutoff_df$cutoff==p,]$sensitivity <- sens_p
cutoff_df[cutoff_df$cutoff==p,]$specificity <- spec_p
}
plot(x=(1-cutoff_df$specificity), y=cutoff_df$sensitivity, type='l',
xlab="1-Specificity", ylab="Sensitivity", main="Receiver Operating Characteristic Plot")
dists <- c()
for (i in 1:nrow(cutoff_df)) {
dist <- sqrt((1-cutoff_df[i,]$sensitivity)^2 + (1-cutoff_df[i,]$specificity)^2)
dists <- c(dists,dist)
}
cutoff_df[which(dists==min(dists)),]
install.packages("gert")
install.packages("gert")
