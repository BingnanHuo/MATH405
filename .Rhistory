plot(NA, NA, ylab ="", xlab = "Lambda", xlim=c(0,10), ylim =c(0,0.01))
lines(lbds, biases_ridge[,1]^2)
lines(lbds, vars_ridge[,1], col="blue")
lines(lbds, mse[,1], col="red")
legend(8,.01,legend=c("biasˆ2", "variance", "MSE"), col=c("black","blue","red"))
plot_est <- function(bias, vars, num) {
}
plot(NA, NA, ylab ="", xlab = "Lambda", xlim=c(0,10), ylim =c(0,0.01))
lines(lbds, biases_ridge[,1]^2)
lines(lbds, vars_ridge[,1], col="blue")
lines(lbds, mse[,1], col="red")
legend(8,.01,legend=c("biasˆ2", "variance", "MSE"), col=c("black","blue","red"), cex=0.8)
plot_est <- function(bias, vars, num) {
}
plot(NA, NA, ylab ="", xlab = "Lambda", xlim=c(0,10), ylim =c(0,0.01))
lines(lbds, biases_ridge[,1]^2)
lines(lbds, vars_ridge[,1], col="blue")
lines(lbds, mse[,1], col="red")
legend(8,.01,legend=c("biasˆ2", "variance", "MSE"), col=c("black","blue","red"), lty=1, cex=0.8)
plot_est <- function(bias, vars, num) {
}
plot(NA, NA, ylab ="", xlab = "Lambda", xlim=c(0,10), ylim =c(0,0.01))
lines(lbds, biases_ridge[,1]^2)
lines(lbds, vars_ridge[,1], col="blue")
lines(lbds, mse[,1], col="red")
legend(legend=c("Biasˆ2", "Variance", "MSE"), col=c("black","blue","red"), lty=1, cex=0.8)
plot_est <- function(bias, vars, num) {
}
plot(NA, NA, ylab ="", xlab = "Lambda", xlim=c(0,10), ylim =c(0,0.01))
lines(lbds, biases_ridge[,1]^2)
lines(lbds, vars_ridge[,1], col="blue")
lines(lbds, mse[,1], col="red")
legend(8, 0.008, legend=c("Biasˆ2", "Variance", "MSE"), col=c("black","blue","red"), lty=1, cex=0.8)
plot_est <- function(bias, vars, num) {
}
plot(NA, NA, ylab ="", xlab = "Lambda", xlim=c(0,10), ylim =c(0,0.008))
lines(lbds, biases_ridge[,1]^2)
lines(lbds, vars_ridge[,1], col="blue")
lines(lbds, mse[,1], col="red")
legend(8, 0.008, legend=c("Biasˆ2", "Variance", "MSE"), col=c("black","blue","red"), lty=1, cex=0.8)
plot_est <- function(bias, vars, num) {
}
plot(NA, NA, ylab ="", xlab = "Lambda", xlim=c(0,10), ylim =c(0,0.008))
lines(lbds, biases_ridge[,1]^2)
lines(lbds, vars_ridge[,1], col="blue")
lines(lbds, mse[,1], col="red")
legend(8, 0.008, legend=c("Biasˆ2", "Variance", "MSE"), col=c("black","blue","red"), lty=1)
plot_est <- function(bias, vars, num) {
}
plot(NA, NA, ylab ="", xlab = "Lambda", xlim=c(0,10), ylim =c(0,0.008))
lines(lbds, biases_ridge[,1]^2)
lines(lbds, vars_ridge[,1], col="blue")
lines(lbds, mse[,1], col="red")
legend(7, 0.008, legend=c("Biasˆ2", "Variance", "MSE"), col=c("black","blue","red"), lty=1)
plot_est <- function(i) {
plot(NA, NA, ylab ="", xlab = "Lambda", main=paste(expression(i),"th","estimator")
xlim=c(0,10), ylim =c(0,0.008))
plot_est <- function(i) {
plot(NA, NA, ylab ="", xlab = "Lambda", main=paste(expression(i),"th","estimator"),
xlim=c(0,10), ylim =c(0,0.008))
lines(lbds, biases_ridge[,i]^2)
lines(lbds, vars_ridge[,i], col="blue")
lines(lbds, mse[,i], col="red")
legend(7, 0.008, legend=c("Biasˆ2", "Variance", "MSE"), col=c("black","blue","red"), lty=1)
}
plot(NA, NA, ylab ="", xlab = "Lambda", xlim=c(0,10), ylim =c(0,0.008))
lines(lbds, biases_ridge[,1]^2)
lines(lbds, vars_ridge[,1], col="blue")
lines(lbds, mse[,1], col="red")
legend(7, 0.008, legend=c("Biasˆ2", "Variance", "MSE"), col=c("black","blue","red"), lty=1)
plot_est <- function(i) {
plot(NA, NA, ylab ="", xlab = "Lambda", main=paste(expression(i),"th","estimator"),
xlim=c(0,10), ylim =c(0,0.008))
lines(lbds, biases_ridge[,i]^2)
lines(lbds, vars_ridge[,i], col="blue")
lines(lbds, mse[,i], col="red")
legend(7, 0.008, legend=c("Biasˆ2", "Variance", "MSE"), col=c("black","blue","red"), lty=1)
}
plot(NA, NA, ylab ="", xlab = "Lambda", xlim=c(0,10), ylim =c(0,0.008))
lines(lbds, biases_ridge[,1]^2)
lines(lbds, vars_ridge[,1], col="blue")
lines(lbds, mse[,1], col="red")
legend(7, 0.008, legend=c("Biasˆ2", "Variance", "MSE"), col=c("black","blue","red"), lty=1)
plot_est <- function(i) {
plot(NA, NA, ylab ="", xlab = "Lambda", main=paste(expression(i),"th","estimator"),
xlim=c(0,10), ylim =c(0,0.008))
lines(lbds, biases_ridge[,i]^2)
lines(lbds, vars_ridge[,i], col="blue")
lines(lbds, mse[,i], col="red")
legend(7, 0.008, legend=c("Biasˆ2", "Variance", "MSE"), col=c("black","blue","red"), lty=1)
}
plot(NA, NA, ylab ="", xlab = "Lambda", xlim=c(0,10), ylim =c(0,0.008))
lines(lbds, biases_ridge[,1]^2)
lines(lbds, vars_ridge[,1], col="blue")
lines(lbds, mse[,1], col="red")
legend(7, 0.008, legend=c("Biasˆ2", "Variance", "MSE"), col=c("black","blue","red"), lty=1)
plot_est <- function(i) {
plot(NA, NA, ylab ="", xlab = "Lambda", main=paste(expression(i),"th","estimator"),
xlim=c(0,10), ylim =c(0,0.008))
lines(lbds, biases_ridge[,i]^2)
lines(lbds, vars_ridge[,i], col="blue")
lines(lbds, mse[,i], col="red")
legend(7, 0.008, legend=c("Biasˆ2", "Variance", "MSE"), col=c("black","blue","red"), lty=1)
}
plot_est(1)
plot_est(2)
plot_est(3)
plot_est(4)
plot_est(5)
plot_est <- function(i) {
plot(NA, NA, ylab ="", xlab = "Lambda", main=paste(i,"th","estimator"),
xlim=c(0,10), ylim =c(0,0.008))
lines(lbds, biases_ridge[,i]^2)
lines(lbds, vars_ridge[,i], col="blue")
lines(lbds, mse[,i], col="red")
legend(7, 0.008, legend=c("Biasˆ2", "Variance", "MSE"), col=c("black","blue","red"), lty=1)
}
plot_est(1)
plot_est(2)
plot_est(3)
plot_est(4)
plot_est(5)
plot_est <- function(i) {
plot(NA, NA, ylab ="", xlab = exp(lambda), main=paste(i,"th","estimator"),
xlim=c(0,10), ylim =c(0,0.008))
lines(lbds, biases_ridge[,i]^2)
lines(lbds, vars_ridge[,i], col="blue")
lines(lbds, mse[,i], col="red")
legend(7, 0.008, legend=c(expression(Bias^2), "Variance", "MSE"), col=c("black","blue","red"), lty=1)
}
plot_est(1)
plot_est <- function(i) {
plot(NA, NA, ylab ="", xlab = exp(\lambda), main=paste(i,"th","estimator"),
plot_est <- function(i) {
plot(NA, NA, ylab ="", xlab = exp(\lambda), main=paste(i,"th","estimator"),
plot_est <- function(i) {
plot(NA, NA, ylab ="", xlab = expression(\lambda), main=paste(i,"th","estimator"),
plot_est <- function(i) {
plot(NA, NA, ylab ="", xlab = expression("\lambda"), main=paste(i,"th","estimator"),
plot_est <- function(i) {
plot(NA, NA, ylab ="", xlab = expression(lambda), main=paste(i,"th","estimator"),
xlim=c(0,10), ylim =c(0,0.008))
lines(lbds, biases_ridge[,i]^2)
lines(lbds, vars_ridge[,i], col="blue")
lines(lbds, mse[,i], col="red")
legend(7, 0.008, legend=c(expression(Bias^2), "Variance", "MSE"), col=c("black","blue","red"), lty=1)
}
plot_est(1)
plot_est(2)
plot_est(3)
plot_est(4)
plot_est(5)
plot_est <- function(i) {
plot(NA, NA, xlab = expression(lambda), ylab ="Values", main=paste(i,"th","estimator"),
xlim=c(0,10), ylim =c(0,0.008))
lines(lbds, biases_ridge[,i]^2)
lines(lbds, vars_ridge[,i], col="blue")
lines(lbds, mse[,i], col="red")
legend(7, 0.008, legend=c(expression(Bias^2), "Variance", "MSE"), col=c("black","blue","red"), lty=1)
}
plot_est(1)
plot_est(2)
plot_est(3)
plot_est(4)
plot_est(5)
library(glmnet)
ridge_cv <- cv.glmnet(X, y, type.measure="mse", alpha=0)
plot(ridge_cv, main="Lambda Values for Ridge Regression with Cross-Validation")
library(glmnet)
ridge_cv <- cv.glmnet(X, y, type.measure="mse", alpha=0)
plot(ridge_cv, main="Lambda Values for Ridge Regression with Cross-Validation")
ridge_cv$lambda.min
ridge_cv$lambda.1se
knitr::opts_chunk$set(echo = TRUE)
dat <- read.csv("Lab7.csv")
y <- matrix(dat$Y, ncol=1)
X <- as.matrix(dat[,-1])
calc_vif <- function(mtx) {
res <- c()
for (i in 1:ncol(mtx)) {
mod <- lm(mtx[,i] ~ mtx[,-i])
rsq <- summary(mod)$r.squared
res <- c(res, 1/(1-rsq))
}
return(res)
}
calc_vif(X)
bias_ridge <- function(X, lambda, beta){
bias <- solve(t(X)%*%X + lambda*diag(1, ncol(t(X)%*%X)) ) %*% (t(X)%*%X) %*% beta - beta
return(bias)
}
var_ridge <- function(X, lambda, sigma_sq){
variance <- sigma_sq * solve(t(X)%*%X + lambda*diag(1, ncol(t(X)%*%X)) ) %*%
(t(X)%*%X) %*% solve(t(X)%*%X + lambda*diag(1, ncol(t(X)%*%X)) )
return(variance)
}
lbd <- 0
beta_ridge <- c(0.398, 0.004, -0.831, 0.292, 0.004)
sigmasq_ridge <- 0.40
bias_ridge(X, lbd, beta_ridge)
diag(var_ridge(X, lbd, sigmasq_ridge))
lbd <- 2
bias_ridge(X, lbd, beta_ridge)
diag(var_ridge(X, lbd, sigmasq_ridge))
lbds <- seq(0,10, length.out=1000)
biases_ridge <- matrix(NA, 1000, 5)
vars_ridge <- matrix(NA, 1000, 5)
for (i in 1:1000) {
this_lbd <- lbds[i]
biases_ridge[i,] <- bias_ridge(X, this_lbd, beta_ridge)
vars_ridge[i,] <- diag(var_ridge(X, this_lbd, sigmasq_ridge))
}
mse <- matrix(NA, 1000, 5)
for (i in 1:1000) {
mse[i,] <- vars_ridge[i,] + (biases_ridge[i,])^2
}
plot_est <- function(i) {
plot(NA, NA, xlab = expression(lambda), ylab ="Values", main=paste(i,"th","estimator"),
xlim=c(0,10), ylim =c(0,0.008))
lines(lbds, biases_ridge[,i]^2)
lines(lbds, vars_ridge[,i], col="blue")
lines(lbds, mse[,i], col="red")
legend(7, 0.008, legend=c(expression(Bias^2), "Variance", "MSE"), col=c("black","blue","red"), lty=1)
}
plot_est(1)
plot_est(2)
plot_est(3)
plot_est(4)
plot_est(5)
library(glmnet)
ridge_cv <- cv.glmnet(X, y, alpha=0)
plot(ridge_cv, main="Lambda Values for Ridge Regression with Cross-Validation")
ridge_cv$lambda.min
ridge_cv$lambda.1se
knitr::opts_chunk$set(echo = TRUE)
dat <- read.csv("Lab7.csv")
y <- matrix(dat$Y, ncol=1)
X <- as.matrix(dat[,-1])
calc_vif <- function(mtx) {
res <- c()
for (i in 1:ncol(mtx)) {
mod <- lm(mtx[,i] ~ mtx[,-i])
rsq <- summary(mod)$r.squared
res <- c(res, 1/(1-rsq))
}
return(res)
}
calc_vif(X)
bias_ridge <- function(X, lambda, beta){
bias <- solve(t(X)%*%X + lambda*diag(1, ncol(t(X)%*%X)) ) %*% (t(X)%*%X) %*% beta - beta
return(bias)
}
var_ridge <- function(X, lambda, sigma_sq){
variance <- sigma_sq * solve(t(X)%*%X + lambda*diag(1, ncol(t(X)%*%X)) ) %*%
(t(X)%*%X) %*% solve(t(X)%*%X + lambda*diag(1, ncol(t(X)%*%X)) )
return(variance)
}
lbd <- 0
beta_ridge <- c(0.398, 0.004, -0.831, 0.292, 0.004)
sigmasq_ridge <- 0.40
bias_ridge(X, lbd, beta_ridge)
diag(var_ridge(X, lbd, sigmasq_ridge))
lbd <- 2
bias_ridge(X, lbd, beta_ridge)
diag(var_ridge(X, lbd, sigmasq_ridge))
lbds <- seq(0,10, length.out=1000)
biases_ridge <- matrix(NA, 1000, 5)
vars_ridge <- matrix(NA, 1000, 5)
for (i in 1:1000) {
this_lbd <- lbds[i]
biases_ridge[i,] <- bias_ridge(X, this_lbd, beta_ridge)
vars_ridge[i,] <- diag(var_ridge(X, this_lbd, sigmasq_ridge))
}
mse <- matrix(NA, 1000, 5)
for (i in 1:1000) {
mse[i,] <- vars_ridge[i,] + (biases_ridge[i,])^2
}
plot_est <- function(i) {
plot(NA, NA, xlab = expression(lambda), ylab ="Values", main=paste(i,"th","estimator"),
xlim=c(0,10), ylim =c(0,0.008))
lines(lbds, biases_ridge[,i]^2)
lines(lbds, vars_ridge[,i], col="blue")
lines(lbds, mse[,i], col="red")
legend(7, 0.008, legend=c(expression(Bias^2), "Variance", "MSE"), col=c("black","blue","red"), lty=1)
}
plot_est(1)
plot_est(2)
plot_est(3)
plot_est(4)
plot_est(5)
library(glmnet)
ridge_cv <- cv.glmnet(X, y, alpha=0)
plot(ridge_cv, main="Lambda Values for Ridge Regression with Cross-Validation")
ridge_cv$lambda.min
ridge_cv$lambda.1se
knitr::opts_chunk$set(echo = TRUE)
dat
mod1 <- lm(Y ~ ., data=dat)
summary(mod1)
par(mfrow=c(2,2))
plot(1,1)
plot(2,2)
par(mfrow=c(2,2))
plot(1,1)
plot(2,2)
par(mfrow=c(2,2))
plot(fitted(mod1), resid(mod1), main="Residuals vs Fitted Values",
xlab="Fitted Values", ylab="Residuals")
plot(dat$X1, dat$Y, main="X1 vs Y", xlab="X1", ylab="Y")
plot(dat$X2, dat$Y, main="X2 vs Y", xlab="X2", ylab="Y")
plot(dat$X3, dat$Y, main="X3 vs Y", xlab="X3", ylab="Y")
Looking at the relationships between $X1,X2,X3$ vs $Y$ though, we see a small positive relationship between $X1,Y$;
crPlots(mod1)
library(car)
crPlots(mod1)
View(dat)
knitr::opts_chunk$set(echo = TRUE)
dat <- read.csv("HW22.csv")
attach(dat)
mod1 <- lm(Y ~ ., data=dat)
summary(mod1)
par(mfrow=c(2,2))
plot(fitted(mod1), resid(mod1), main="Residuals vs Fitted Values",
xlab="Fitted Values", ylab="Residuals")
plot(X1, Y, main="X1 vs Y", xlab="X1", ylab="Y")
plot(X2, Y, main="X2 vs Y", xlab="X2", ylab="Y")
plot(X3, Y, main="X3 vs Y", xlab="X3", ylab="Y")
library(car)
crPlots(mod1)
mod2 <- lm(Y~.+X1^2, data=dat)
crPlot3d(mod2)
install.packages("car")
install.packages("rgl")
knitr::opts_chunk$set(echo = TRUE)
dat <- read.csv("HW22.csv")
attach(dat)
mod1 <- lm(Y ~ ., data=dat)
summary(mod1)
par(mfrow=c(2,2))
plot(fitted(mod1), resid(mod1), main="Residuals vs Fitted Values",
xlab="Fitted Values", ylab="Residuals")
plot(X1, Y, main="X1 vs Y", xlab="X1", ylab="Y")
plot(X2, Y, main="X2 vs Y", xlab="X2", ylab="Y")
plot(X3, Y, main="X3 vs Y", xlab="X3", ylab="Y")
library(car)
crPlots(mod1)
mod2 <- lm(Y~.+X1^2, data=dat)
summary(mod2)
crPlot3d(mod2)
install.packages("effects")
View(dat)
mod2 <- lm(Y~.+X1^2, data=dat)
summary(mod2)
crPlot3d(mod2)
knitr::opts_chunk$set(echo = TRUE)
dat <- read.csv("HW22.csv")
attach(dat)
mod1 <- lm(Y ~ ., data=dat)
summary(mod1)
par(mfrow=c(2,2))
plot(fitted(mod1), resid(mod1), main="Residuals vs Fitted Values",
xlab="Fitted Values", ylab="Residuals")
plot(X1, Y, main="X1 vs Y", xlab="X1", ylab="Y")
plot(X2, Y, main="X2 vs Y", xlab="X2", ylab="Y")
plot(X3, Y, main="X3 vs Y", xlab="X3", ylab="Y")
library(car)
crPlots(mod1)
mod2 <- lm(Y~.+X1^2, data=dat)
summary(mod2)
crPlot(mod2)
mod2 <- lm(Y~X1+X2+X3+X1^2, data=dat)
summary(mod2)
.
mod2 <- lm(Y~.+X1^2, data=dat)
summary(mod2)
2+X3
mod2 <- lm(Y~X1+X2+X3+X1^2, data=dat)
summary(mod2)
mod2 <- lm(Y~.+X1**2, data=dat)
summary(mod2)
crPlot(mod2)
mod2 <- lm(Y~.+X1**2, data=dat)
summary(mod2)
crPlot(mod2)
mod2 <- lm(Y~.+X1**2, data=dat)
summary(mod2)
crPlot(mod2)
mod2 <- lm(Y~.+X1**2, data=dat)
summary(mod2)
crPlot(mod2)
3^2
mod2 <- lm(Y~.+I(X1^2), data=dat)
summary(mod2)
crPlot(mod2)
mod2 <- lm(Y~.+I(X1^2), data=dat)
summary(mod2)
crPlot(mod2)
dat2$X1^2 <- X1^2
dat2 <- dat
dat2$X1^2 <- X1^2
dat2 <- dat
dat2$X1_2 <- X1^2
mod2 <- lm(Y~.+I(X1^2), data=dat)
summary(mod2)
crPlot(mod2)
dat2 <- dat
dat2$X1_2 <- X1^2
mod2 <- lm(Y~., data=dat2)
summary(mod2)
crPlot(mod2)
dat2 <- dat
dat2$
mod2 <- lm(Y~.+I(X1^2), data=dat)
dat2 <- dat
mod2 <- lm(Y~.+I(X1^2), data=dat)
summary(mod2)
crPlots(mod2)
mod3 <- lm(Y~.+X1^2+X1^3, data=dat)
summary(mod3)
crPlots(mod3)
mod3 <- lm(Y~.+I(X1^2)+I(X1^3), data=dat)
summary(mod3)
crPlots(mod3)
mod3 <- lm(Y~.+I(X1^2)+I(X3^2), data=dat)
summary(mod3)
crPlots(mod3)
detach(dat)
wine <- read.csv("winequality.csv")
attach(wine)
wine
mod_wine <- lm(quality~., data=wine)
summary(mod_wine)
crPlots(mod_wine)
knitr::opts_chunk$set(echo = TRUE)
dat <- read.csv("HW22.csv")
attach(dat)
mod1 <- lm(Y ~ ., data=dat)
summary(mod1)
par(mfrow=c(2,2))
plot(fitted(mod1), resid(mod1), main="Residuals vs Fitted Values",
xlab="Fitted Values", ylab="Residuals")
plot(X1, Y, main="X1 vs Y", xlab="X1", ylab="Y")
plot(X2, Y, main="X2 vs Y", xlab="X2", ylab="Y")
plot(X3, Y, main="X3 vs Y", xlab="X3", ylab="Y")
library(car)
crPlots(mod1)
mod2 <- lm(Y~.+I(X1^2), data=dat)
summary(mod2)
crPlots(mod2)
mod3 <- lm(Y~.+I(X1^2)+I(X3^2), data=dat)
summary(mod3)
crPlots(mod3)
detach(dat)
wine <- read.csv("winequality.csv")
attach(wine)
mod_wine <- lm(quality~., data=wine)
summary(mod_wine)
round(cor(X),3)
X <- scale(as.matrix(wine[,-1]))
round(cor(X),3)
pairs(X)
View(mod_wine)
View(wine)
X <- scale(as.matrix(wine[,-12]))
round(cor(X),3)
e <- eigen(t(X)%*%X)
e
V <- e$vectors
lam <- e$values
plot(lam, xlab='Eigenvalue Number', ylab='Eigenvalue Size', main='Scree Plot')
lines(lam)
pi <- lam/sum(lam)
pi
pi.cumul <- c()
for (i in 1:length(lam)) {
pi.cumul[i] <- sum(pi[1:i])
}
pi.cumul
plot(pi.cumul, xlab='Eigenvalue Number', ylab='Cumulative Proportion', main='')
lines(pi.cumul)
abline(0.85, 0, lty=2)
abline(0.90, 0, lty=2)
abline(0.95, 0, lty=2)
diag(var(Z))
Z <- X%*%V
diag(var(Z))
pcr <- lm(quality ~ Z)
summary(pcr)
Z
Z <- X%*%V
diag(var(Z))
pcr <- lm(quality ~ Z[,1:8])
summary(pcr)
pcr <- lm(quality ~ Z[,1:9])
summary(pcr)
pcr <- lm(quality ~ Z[,1:11])
summary(pcr)
pcr <- lm(quality ~ Z[,1:7])
summary(pcr)
pcr <- lm(quality ~ Z[,1:6])
summary(pcr)
pcr <- lm(quality ~ Z[,1:5])
summary(pcr)
pcr <- lm(quality ~ Z[,1:6])
summary(pcr)
b_hat_pca <- as.matrix(pcr$coefficients[2:7], nr=6)
b_hat_pca <- as.matrix(pcr$coefficients[2:7], nr=6)
b_hat <- V%*%b_hat_pca
pcr2 <- lm(quality ~ Z)
b_hat_pca <- as.matrix(pcr2$coefficients[2:12], nr=11)
b_hat <- V%*%b_hat_pca
b_hat
